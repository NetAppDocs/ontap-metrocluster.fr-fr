---
permalink: install-ip/task_test_the_mcc_configuration.html 
sidebar: sidebar 
keywords: test, metrocluster, configuration, failure, correct, operation, metrocluster, verify, negotiate, switchover, heal, manual, switchback, power, line, disruption, loss, single, storage, shelf 
summary: 'Vous pouvez tester les scénarios d"échec pour vérifier le bon fonctionnement de la configuration MetroCluster.' 
---
= Test de la configuration MetroCluster
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Vous pouvez tester les scénarios d'échec pour vérifier le bon fonctionnement de la configuration MetroCluster.



== Vérification du basculement négocié

Vous pouvez tester le basculement négocié (planifié) pour confirmer la disponibilité ininterrompue des données.

.Description de la tâche
Ce test vérifie que la disponibilité des données n'est pas affectée (à l'exception des protocoles Microsoft Server message Block (SMB) et Solaris Fibre Channel) en commutant le cluster sur le second data Center.

Ce test devrait prendre environ 30 minutes.

Cette procédure présente les résultats attendus suivants :

* Le `metrocluster switchover` la commande affiche une invite d'avertissement.
+
Si vous répondez `yes` à l'invite, le site dont la commande est émise bascule sur le site partenaire.



Pour les configurations MetroCluster IP :

* Pour ONTAP 9.4 et versions antérieures :
+
** Les agrégats en miroir seront dégradés après le basculement négocié.


* Pour ONTAP 9.5 et versions ultérieures :
+
** Les agrégats en miroir resteront dans un état normal en cas d'accès au stockage distant.
** En cas de perte de l'accès au stockage distant, les agrégats en miroir sont dégradés après le basculement négocié.


* Pour ONTAP 9.8 et versions ultérieures :
+
** En cas de perte de l'accès au stockage distant, les agrégats non mis en miroir qui se trouvent sur le site de reprise après incident deviennent indisponibles. Cela peut entraîner une panne du contrôleur.




.Étapes
. Vérifier que tous les nœuds sont en mode configuré et normal :
+
`metrocluster node show`

+
[listing]
----
cluster_A::>  metrocluster node show

Cluster                        Configuration State    Mode
------------------------------ ---------------------- ------------------------
 Local: cluster_A               configured             normal
Remote: cluster_B               configured             normal
----
. Commencer l'opération de basculement :
+
`metrocluster switchover`

+
[listing]
----
cluster_A::> metrocluster switchover
Warning: negotiated switchover is about to start. It will stop all the data Vservers on cluster "cluster_B" and
automatically re-start them on cluster "cluster_A". It will finally gracefully shutdown cluster "cluster_B".
----
. Vérifier que le cluster local est en mode configuré et basculement :
+
`metrocluster node show`

+
[listing]
----
cluster_A::>  metrocluster node show

Cluster                        Configuration State    Mode
------------------------------ ---------------------- ------------------------
Local: cluster_A                configured             switchover
Remote: cluster_B               not-reachable          -
              configured             normal
----
. Vérifier que l'opération de basculement a réussi :
+
`metrocluster operation show`

+
[listing]
----
cluster_A::>  metrocluster operation show

cluster_A::> metrocluster operation show
  Operation: switchover
      State: successful
 Start Time: 2/6/2016 13:28:50
   End Time: 2/6/2016 13:29:41
     Errors: -
----
. Utilisez le `vserver show` et `network interface show` Les commandes qui permettent de vérifier que les SVM et les LIF de DR sont bien en ligne.




== Vérification de la correction et du rétablissement manuel

Vous pouvez tester les opérations de rétablissement et de rétablissement manuel pour vérifier que la disponibilité des données n'est pas affectée (sauf dans le cas des configurations FC SMB et Solaris) en repassant le cluster au data Center d'origine après un basculement négocié.

.Description de la tâche
Ce test devrait prendre environ 30 minutes.

Cette procédure devrait permettre de revenir aux nœuds de départ des services.

Les étapes de correction ne sont pas nécessaires sur les systèmes exécutant ONTAP 9.5 ou version ultérieure, sur lesquels la correction est automatiquement exécutée après un basculement négocié. Sur les systèmes exécutant ONTAP 9.6 et versions ultérieures, la correction est également effectuée automatiquement après un basculement non planifié.

.Étapes
. Si le système exécute ONTAP 9.4 ou une version antérieure, procédez à l'ajustement de l'agrégat de données :
+
`metrocluster heal aggregates`

+
L'exemple suivant montre la réussite de la commande :

+
[listing]
----
cluster_A::> metrocluster heal aggregates
[Job 936] Job succeeded: Heal Aggregates is successful.
----
. Si le système exécute ONTAP 9.4 ou une version antérieure, procédez à une correction de l'agrégat racine :
+
`metrocluster heal root-aggregates`

+
Cette étape est requise dans les configurations suivantes :

+
** Configurations FC MetroCluster.
** Les configurations IP de MetroCluster exécutant ONTAP 9.4 ou une version antérieure. L'exemple suivant montre la réussite de la commande :


+
[listing]
----
cluster_A::> metrocluster heal root-aggregates
[Job 937] Job succeeded: Heal Root Aggregates is successful.
----
. Vérifiez que la correction est terminée :
+
`metrocluster node show`

+
L'exemple suivant montre la réussite de la commande :

+
[listing]
----
cluster_A::> metrocluster node show
DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_A
              node_A_1         configured     enabled   heal roots completed
      cluster_B
              node_B_2         unreachable    -         switched over
42 entries were displayed.metrocluster operation show
----
+
Si l'opération de correction automatique échoue pour une raison quelconque, vous devez émettre le `metrocluster heal` Commandes manuelles comme effectuées dans les versions ONTAP antérieures à ONTAP 9.5. Vous pouvez utiliser le `metrocluster operation show` et `metrocluster operation history show -instance` commandes permettant de contrôler l'état de la correction et de déterminer la cause d'une défaillance.

. Vérifier que tous les agrégats sont mis en miroir :
+
`storage aggregate show`

+
L'exemple suivant montre que tous les agrégats ont un statut RAID en miroir :

+
[listing]
----
cluster_A::> storage aggregate show
cluster Aggregates:
Aggregate Size     Available Used% State   #Vols  Nodes       RAID Status
--------- -------- --------- ----- ------- ------ ----------- ------------
data_cluster
            4.19TB    4.13TB    2% online       8 node_A_1    raid_dp,
                                                              mirrored,
                                                              normal
root_cluster
           715.5GB   212.7GB   70% online       1 node_A_1    raid4,
                                                              mirrored,
                                                              normal
cluster_B Switched Over Aggregates:
Aggregate Size     Available Used% State   #Vols  Nodes       RAID Status
--------- -------- --------- ----- ------- ------ ----------- ------------
data_cluster_B
            4.19TB    4.11TB    2% online       5 node_A_1    raid_dp,
                                                              mirrored,
                                                              normal
root_cluster_B    -         -     - unknown      - node_A_1   -
----
. Vérifier l'état de la restauration en cas de rétablissement :
+
`metrocluster node show`

+
[listing]
----
cluster_A::> metrocluster node show
DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_A
             node_A_1            configured     enabled   heal roots completed
      cluster_B
             node_B_2            configured     enabled   waiting for switchback
                                                          recovery
2 entries were displayed.
----
. Effectuez le rétablissement :
+
`metrocluster switchback`

+
[listing]
----
cluster_A::> metrocluster switchback
[Job 938] Job succeeded: Switchback is successful.Verify switchback
----
. Confirmer l'état des nœuds :
+
`metrocluster node show`

+
[listing]
----
cluster_A::> metrocluster node show
DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_A
              node_A_1         configured     enabled   normal
      cluster_B
              node_B_2         configured     enabled   normal

2 entries were displayed.
----
. Confirmer l'état de l'opération MetroCluster :
+
`metrocluster operation show`

+
Le résultat doit indiquer un état réussi.

+
[listing]
----
cluster_A::> metrocluster operation show
  Operation: switchback
      State: successful
 Start Time: 2/6/2016 13:54:25
   End Time: 2/6/2016 13:56:15
     Errors: -
----




== Vérification du fonctionnement après une interruption de la ligne d'alimentation

Vous pouvez tester la réponse de la configuration MetroCluster à la défaillance d'une PDU.

.Description de la tâche
Il est recommandé de connecter un composant à des blocs d'alimentation distincts. Si les deux blocs d'alimentation sont connectés à la même unité de distribution électrique et qu'une interruption électrique se produit, le site peut être en panne ou si un tiroir complet risque de ne plus être disponible. La défaillance d'une ligne d'alimentation est testée pour vérifier qu'il n'y a pas de défaut de câblage susceptible d'entraîner une interruption du service.

Ce test devrait prendre environ 15 minutes.

Ce test nécessite la mise hors tension de toutes les PDU de gauche, puis toutes les PDU de droite sur tous les racks contenant les composants MetroCluster.

Cette procédure présente les résultats attendus suivants :

* Les erreurs doivent être générées lorsque les PDU sont déconnectées.
* Aucun basculement ni perte de service ne doit se produire.


.Étapes
. Coupez l'alimentation des PDU situées sur le côté gauche du rack contenant les composants MetroCluster.
. Surveiller le résultat sur la console :
+
`system environment sensors show -state fault`

+
`storage shelf show -errors`

+
[listing]
----
cluster_A::> system environment sensors show -state fault

Node Sensor 			State Value/Units Crit-Low Warn-Low Warn-Hi Crit-Hi
---- --------------------- ------ ----------- -------- -------- ------- -------
node_A_1
		PSU1 			fault
							PSU_OFF
		PSU1 Pwr In OK 	fault
							FAULT
node_A_2
		PSU1 			fault
							PSU_OFF
		PSU1 Pwr In OK 	fault
							FAULT
4 entries were displayed.

cluster_A::> storage shelf show -errors
    Shelf Name: 1.1
     Shelf UID: 50:0a:09:80:03:6c:44:d5
 Serial Number: SHFHU1443000059

Error Type          Description
------------------  ---------------------------
Power               Critical condition is detected in storage shelf power supply unit "1". The unit might fail.Reconnect PSU1
----
. Remettez l'alimentation en marche sur les unités de distribution d'alimentation de gauche.
. Assurez-vous que ONTAP efface la condition d'erreur.
. Répétez les étapes précédentes avec les PDU de droite.




== Vérification de l'opération après la perte d'un tiroir de stockage

Vous pouvez tester la panne d'un tiroir de stockage pour vérifier qu'il n'y a pas de point de défaillance unique.

.Description de la tâche
Cette procédure présente les résultats attendus suivants :

* Un message d'erreur doit être signalé par le logiciel de surveillance.
* Aucun basculement ni perte de service ne doit se produire.
* La resynchronisation du miroir démarre automatiquement après la restauration de la défaillance matérielle.


.Étapes
. Vérifier l'état du basculement du stockage :
+
`storage failover show`

+
[listing]
----
cluster_A::> storage failover show

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node_A_1       node_A_2       true     Connected to node_A_2
node_A_2       node_A_1       true     Connected to node_A_1
2 entries were displayed.
----
. Vérifier le statut de l'agrégat :
+
`storage aggregate show`

+
[listing]
----
cluster_A::> storage aggregate show

cluster Aggregates:
Aggregate     Size Available Used% State   #Vols  Nodes            RAID Status
--------- -------- --------- ----- ------- ------ ---------------- ------------
node_A_1data01_mirrored
            4.15TB    3.40TB   18% online       3 node_A_1       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_1root
           707.7GB   34.29GB   95% online       1 node_A_1       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_2_data01_mirrored
            4.15TB    4.12TB    1% online       2 node_A_2       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_2_data02_unmirrored
            2.18TB    2.18TB    0% online       1 node_A_2       raid_dp,
                                                                   normal
node_A_2_root
           707.7GB   34.27GB   95% online       1 node_A_2       raid_dp,
                                                                   mirrored,
                                                                   normal
----
. Vérifier que tous les SVM et volumes de données sont en ligne et transfère les données :
+
`vserver show -type data`

+
`network interface show -fields is-home false`

+
`volume show !vol0,!MDV*`

+
[listing]
----
cluster_A::> vserver show -type data
                               Admin      Operational Root
Vserver     Type    Subtype    State      State       Volume     Aggregate
----------- ------- ---------- ---------- ----------- ---------- ----------
SVM1        data    sync-source           running     SVM1_root  node_A_1_data01_mirrored
SVM2        data    sync-source	          running     SVM2_root  node_A_2_data01_mirrored

cluster_A::> network interface show -fields is-home false
There are no entries matching your query.

cluster_A::> volume show !vol0,!MDV*
Vserver   Volume       Aggregate    State      Type       Size  Available Used%
--------- ------------ ------------ ---------- ---- ---------- ---------- -----
SVM1
          SVM1_root
                       node_A_1data01_mirrored
                                    online     RW         10GB     9.50GB    5%
SVM1
          SVM1_data_vol
                       node_A_1data01_mirrored
                                    online     RW         10GB     9.49GB    5%
SVM2
          SVM2_root
                       node_A_2_data01_mirrored
                                    online     RW         10GB     9.49GB    5%
SVM2
          SVM2_data_vol
                       node_A_2_data02_unmirrored
                                    online     RW          1GB    972.6MB    5%
----
. Identifiez un tiroir dans le pool 1 pour le nœud « Node_A_2 » hors tension afin de simuler une panne matérielle soudaine :
+
`storage aggregate show -r -node _node-name_ !*root`

+
Le tiroir que vous sélectionnez doit contenir des lecteurs faisant partie d'un agrégat de données en miroir.

+
Dans l'exemple suivant, l'ID de tiroir « 31 » est sélectionné pour échouer.

+
[listing]
----
cluster_A::> storage aggregate show -r -node node_A_2 !*root
Owner Node: node_A_2
 Aggregate: node_A_2_data01_mirrored (online, raid_dp, mirrored) (block checksums)
  Plex: /node_A_2_data01_mirrored/plex0 (online, normal, active, pool0)
   RAID Group /node_A_2_data01_mirrored/plex0/rg0 (normal, block checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     dparity  2.30.3                       0   BSAS    7200  827.7GB  828.0GB (normal)
     parity   2.30.4                       0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.6                       0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.8                       0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.5                       0   BSAS    7200  827.7GB  828.0GB (normal)

  Plex: /node_A_2_data01_mirrored/plex4 (online, normal, active, pool1)
   RAID Group /node_A_2_data01_mirrored/plex4/rg0 (normal, block checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     dparity  1.31.7                       1   BSAS    7200  827.7GB  828.0GB (normal)
     parity   1.31.6                       1   BSAS    7200  827.7GB  828.0GB (normal)
     data     1.31.3                       1   BSAS    7200  827.7GB  828.0GB (normal)
     data     1.31.4                       1   BSAS    7200  827.7GB  828.0GB (normal)
     data     1.31.5                       1   BSAS    7200  827.7GB  828.0GB (normal)

 Aggregate: node_A_2_data02_unmirrored (online, raid_dp) (block checksums)
  Plex: /node_A_2_data02_unmirrored/plex0 (online, normal, active, pool0)
   RAID Group /node_A_2_data02_unmirrored/plex0/rg0 (normal, block checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     dparity  2.30.12                      0   BSAS    7200  827.7GB  828.0GB (normal)
     parity   2.30.22                      0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.21                      0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.20                      0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.14                      0   BSAS    7200  827.7GB  828.0GB (normal)
15 entries were displayed.
----
. Mettez physiquement hors tension la tablette que vous avez sélectionnée.
. Vérifier à nouveau l'état de l'agrégat :
+
`storage aggregate show`

+
`storage aggregate show -r -node node_A_2 !*root`

+
L'agrégat avec disques du shelf hors tension doit avoir un état RAID « dégradé », et les disques du plex affecté doivent avoir un état en panne, comme illustré ci-dessous :

+
[listing]
----
cluster_A::> storage aggregate show
Aggregate     Size Available Used% State   #Vols  Nodes            RAID Status
--------- -------- --------- ----- ------- ------ ---------------- ------------
node_A_1data01_mirrored
            4.15TB    3.40TB   18% online       3 node_A_1       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_1root
           707.7GB   34.29GB   95% online       1 node_A_1       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_2_data01_mirrored
            4.15TB    4.12TB    1% online       2 node_A_2       raid_dp,
                                                                   mirror
                                                                   degraded
node_A_2_data02_unmirrored
            2.18TB    2.18TB    0% online       1 node_A_2       raid_dp,
                                                                   normal
node_A_2_root
           707.7GB   34.27GB   95% online       1 node_A_2       raid_dp,
                                                                   mirror
                                                                   degraded
cluster_A::> storage aggregate show -r -node node_A_2 !*root
Owner Node: node_A_2
 Aggregate: node_A_2_data01_mirrored (online, raid_dp, mirror degraded) (block checksums)
  Plex: /node_A_2_data01_mirrored/plex0 (online, normal, active, pool0)
   RAID Group /node_A_2_data01_mirrored/plex0/rg0 (normal, block checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     dparity  2.30.3                       0   BSAS    7200  827.7GB  828.0GB (normal)
     parity   2.30.4                       0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.6                       0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.8                       0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.5                       0   BSAS    7200  827.7GB  828.0GB (normal)

  Plex: /node_A_2_data01_mirrored/plex4 (offline, failed, inactive, pool1)
   RAID Group /node_A_2_data01_mirrored/plex4/rg0 (partial, none checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     dparity  FAILED                       -   -          -  827.7GB        - (failed)
     parity   FAILED                       -   -          -  827.7GB        - (failed)
     data     FAILED                       -   -          -  827.7GB        - (failed)
     data     FAILED                       -   -          -  827.7GB        - (failed)
     data     FAILED                       -   -          -  827.7GB        - (failed)

 Aggregate: node_A_2_data02_unmirrored (online, raid_dp) (block checksums)
  Plex: /node_A_2_data02_unmirrored/plex0 (online, normal, active, pool0)
   RAID Group /node_A_2_data02_unmirrored/plex0/rg0 (normal, block checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     dparity  2.30.12                      0   BSAS    7200  827.7GB  828.0GB (normal)
     parity   2.30.22                      0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.21                      0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.20                      0   BSAS    7200  827.7GB  828.0GB (normal)
     data     2.30.14                      0   BSAS    7200  827.7GB  828.0GB (normal)
15 entries were displayed.
----
. Vérifier que les données sont servies et que tous les volumes sont toujours en ligne :
+
`vserver show -type data`

+
`network interface show -fields is-home false`

+
`volume show !vol0,!MDV*`

+
[listing]
----
cluster_A::> vserver show -type data

cluster_A::> vserver show -type data
                               Admin      Operational Root
Vserver     Type    Subtype    State      State       Volume     Aggregate
----------- ------- ---------- ---------- ----------- ---------- ----------
SVM1        data    sync-source           running     SVM1_root  node_A_1_data01_mirrored
SVM2        data    sync-source	          running     SVM2_root  node_A_1_data01_mirrored

cluster_A::> network interface show -fields is-home false
There are no entries matching your query.

cluster_A::> volume show !vol0,!MDV*
Vserver   Volume       Aggregate    State      Type       Size  Available Used%
--------- ------------ ------------ ---------- ---- ---------- ---------- -----
SVM1
          SVM1_root
                       node_A_1data01_mirrored
                                    online     RW         10GB     9.50GB    5%
SVM1
          SVM1_data_vol
                       node_A_1data01_mirrored
                                    online     RW         10GB     9.49GB    5%
SVM2
          SVM2_root
                       node_A_1data01_mirrored
                                    online     RW         10GB     9.49GB    5%
SVM2
          SVM2_data_vol
                       node_A_2_data02_unmirrored
                                    online     RW          1GB    972.6MB    5%
----
. Mettez le shelf sous tension physique.
+
La resynchronisation démarre automatiquement.

. Vérifier que la resynchronisation a démarré :
+
`storage aggregate show`

+
L'agrégat affecté doit avoir l'état de « resynchronisation », comme l'illustre l'exemple suivant :

+
[listing]
----
cluster_A::> storage aggregate show
cluster Aggregates:
Aggregate     Size Available Used% State   #Vols  Nodes            RAID Status
--------- -------- --------- ----- ------- ------ ---------------- ------------
node_A_1_data01_mirrored
            4.15TB    3.40TB   18% online       3 node_A_1       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_1_root
           707.7GB   34.29GB   95% online       1 node_A_1       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_2_data01_mirrored
            4.15TB    4.12TB    1% online       2 node_A_2       raid_dp,
                                                                   resyncing
node_A_2_data02_unmirrored
            2.18TB    2.18TB    0% online       1 node_A_2       raid_dp,
                                                                   normal
node_A_2_root
           707.7GB   34.27GB   95% online       1 node_A_2       raid_dp,
                                                                   resyncing
----
. Surveiller l'agrégat pour vérifier que la resynchronisation est terminée :
+
`storage aggregate show`

+
L'agrégat affecté doit avoir un statut RAID « normal », comme illustré dans l'exemple suivant :

+
[listing]
----
cluster_A::> storage aggregate show
cluster Aggregates:
Aggregate     Size Available Used% State   #Vols  Nodes            RAID Status
--------- -------- --------- ----- ------- ------ ---------------- ------------
node_A_1data01_mirrored
            4.15TB    3.40TB   18% online       3 node_A_1       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_1root
           707.7GB   34.29GB   95% online       1 node_A_1       raid_dp,
                                                                   mirrored,
                                                                   normal
node_A_2_data01_mirrored
            4.15TB    4.12TB    1% online       2 node_A_2       raid_dp,
                                                                   normal
node_A_2_data02_unmirrored
            2.18TB    2.18TB    0% online       1 node_A_2       raid_dp,
                                                                   normal
node_A_2_root
           707.7GB   34.27GB   95% online       1 node_A_2       raid_dp,
                                                                   resyncing
----

