---
permalink: transition/task_configure_transition.html 
sidebar: sidebar 
keywords: Generating and applying RCFs to the new IP switches, review, requirement, preparing, prepare, transition, perform, procedure, order, completing, complete, step, task, moving, move, controller, storage, shelves, shelf, exist, configuration, direct, metrocluster, fc, ip, verify, health, removing, remove, tiebreaker, monitor, software, generating, generate, apply, rcf, switch, controller, configure, prepare, preparing 
summary: Pour préparer la configuration à la transition, vous ajoutez les nouveaux nœuds à la configuration MetroCluster existante, puis déplacez les données vers les nouveaux nœuds. 
---
= Configuration de MetroCluster pour la transition
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Pour préparer la configuration à la transition, vous ajoutez les nouveaux nœuds à la configuration MetroCluster existante, puis déplacez les données vers les nouveaux nœuds.



== Envoi d'un message AutoSupport personnalisé avant la maintenance

Avant d'effectuer la maintenance, vous devez envoyer un message AutoSupport pour informer le support technique de NetApp que la maintenance est en cours. Informer le support technique que la maintenance est en cours empêche l'ouverture d'un dossier en supposant une interruption de l'activité.

.Description de la tâche
Cette tâche doit être effectuée sur chaque site MetroCluster.

.Étapes
. Pour éviter la génération automatique de dossiers de demande de support, envoyez un message AutoSupport pour indiquer que la maintenance est en cours :
+
`system node autosupport invoke -node * -type all -message MAINT=maintenance-window-in-hours`

+
"maintenance-fenêtre-en-heures" spécifie la durée de la fenêtre de maintenance, avec un maximum de 72 heures. Si la maintenance est terminée avant le temps écoulé, vous pouvez appeler un message AutoSupport indiquant la fin de la période de maintenance :

+
`system node autosupport invoke -node * -type all -message MAINT=end`

. Répétez la commande sur le cluster partenaire.




== Activation du mode transition et désactivation de la haute disponibilité du cluster

Vous devez activer le mode de transition MetroCluster pour permettre aux anciens et nouveaux nœuds de fonctionner ensemble dans la configuration MetroCluster, et désactiver le cluster HA.

. Activer la transition :
+
.. Changement au niveau de privilège avancé :
+
`set -privilege advanced`

.. Activer le mode de transition :
+
`metrocluster transition enable -transition-mode non-disruptive`

+

NOTE: Exécutez cette commande sur un seul cluster.

+
....
cluster_A::*> metrocluster transition enable -transition-mode non-disruptive

Warning: This command enables the start of a "non-disruptive" MetroCluster
         FC-to-IP transition. It allows the addition of hardware for another DR
         group that uses IP fabrics, and the removal of a DR group that uses FC
         fabrics. Clients will continue to access their data during a
         non-disruptive transition.

         Automatic unplanned switchover will also be disabled by this command.
Do you want to continue? {y|n}: y

cluster_A::*>

....
.. Retour au niveau de privilège admin :
+
`set -privilege admin`



. Vérifiez que la transition est activée sur les deux clusters.
+
....

cluster_A::> metrocluster transition show-mode
Transition Mode

non-disruptive

cluster_A::*>


cluster_B::*> metrocluster transition show-mode
Transition Mode

non-disruptive

Cluster_B::>

....
. Désactivation du cluster HA
+

NOTE: Vous devez exécuter cette commande sur les deux clusters.

+
....
cluster_A::*> cluster ha modify -configured false

Warning: This operation will unconfigure cluster HA. Cluster HA must be
configured on a two-node cluster to ensure data access availability in
the event of storage failover.
Do you want to continue? {y|n}: y
Notice: HA is disabled.

cluster_A::*>


cluster_B::*> cluster ha modify -configured false

Warning: This operation will unconfigure cluster HA. Cluster HA must be
configured on a two-node cluster to ensure data access availability in
the event of storage failover.
Do you want to continue? {y|n}: y
Notice: HA is disabled.

cluster_B::*>
....
. Vérifiez que la haute disponibilité du cluster est désactivée.
+

NOTE: Vous devez exécuter cette commande sur les deux clusters.

+
....
cluster_A::> cluster ha show

High Availability Configured: false
Warning: Cluster HA has not been configured. Cluster HA must be configured
on a two-node cluster to ensure data access availability in the
event of storage failover. Use the "cluster ha modify -configured
true" command to configure cluster HA.

cluster_A::>

cluster_B::> cluster ha show

High Availability Configured: false
Warning: Cluster HA has not been configured. Cluster HA must be configured
on a two-node cluster to ensure data access availability in the
event of storage failover. Use the "cluster ha modify -configured
true" command to configure cluster HA.

cluster_B::>
....




== Connexion des nœuds IP MetroCluster aux clusters

Vous devez ajouter les quatre nouveaux nœuds IP MetroCluster à la configuration MetroCluster existante.

.Description de la tâche
Vous devez effectuer cette tâche sur les deux clusters.

.Étapes
. Ajoutez les nœuds IP MetroCluster à la configuration MetroCluster existante.
+
.. Reliez le premier nœud IP MetroCluster (node_A_3-IP) à la configuration FC MetroCluster existante.
+
....

Welcome to the cluster setup wizard.

You can enter the following commands at any time:
  "help" or "?" - if you want to have a question clarified,
  "back" - if you want to change previously answered questions, and
  "exit" or "quit" - if you want to quit the cluster setup wizard.
     Any changes you made before quitting will be saved.

You can return to cluster setup at any time by typing "cluster setup".
To accept a default or omit a question, do not enter a value.

This system will send event messages and periodic reports to NetApp Technical
Support. To disable this feature, enter autosupport modify -support disable
within 24 hours.

Enabling AutoSupport can significantly speed problem determination and
resolution, should a problem occur on your system.
For further information on AutoSupport, see:
http://support.netapp.com/autosupport/

Type yes to confirm and continue {yes}: yes

Enter the node management interface port [e0M]:
Enter the node management interface IP address: 172.17.8.93
Enter the node management interface netmask: 255.255.254.0
Enter the node management interface default gateway: 172.17.8.1
A node management interface on port e0M with IP address 172.17.8.93 has been created.

Use your web browser to complete cluster setup by accessing https://172.17.8.93

Otherwise, press Enter to complete cluster setup using the command line
interface:

Do you want to create a new cluster or join an existing cluster? {create, join}:
join


Existing cluster interface configuration found:

Port    MTU     IP              Netmask
e0c     9000    169.254.148.217 255.255.0.0
e0d     9000    169.254.144.238 255.255.0.0

Do you want to use this configuration? {yes, no} [yes]: yes
.
.
.
....
.. Reliez le deuxième nœud IP MetroCluster (node_A_4-IP) à la configuration FC MetroCluster existante.


. Répétez ces étapes pour joindre le noeud_B_3-IP et le noeud_B_4-IP au cluster_B.




== Configuration des LIFs intercluster, création des interfaces MetroCluster, et mise en miroir des agrégats racines

Vous devez créer des LIF de peering de cluster, créer les interfaces MetroCluster sur les nouveaux nœuds IP MetroCluster.

.Description de la tâche
Le port home utilisé dans les exemples est spécifique à la plate-forme. Vous devez utiliser le port d'accueil approprié spécifique à la plate-forme de nœud IP MetroCluster.

.Étapes
. Sur les nouveaux nœuds IP MetroCluster, link:../install-ip/task_sw_config_configure_clusters.html#configuring-intercluster-lifs-for-cluster-peering["Configurer les LIFs intercluster"].
. Sur chaque site, vérifiez que le peering de cluster est configuré :
+
`cluster peer show`

+
L'exemple suivant montre la configuration de peering de cluster sur cluster_A :

+
....
cluster_A:> cluster peer show
Peer Cluster Name         Cluster Serial Number Availability   Authentication
------------------------- --------------------- -------------- --------------
cluster_B                 1-80-000011           Available      ok
....
+
L'exemple suivant montre la configuration de peering de cluster sur cluster_B :

+
....
cluster_B:> cluster peer show
Peer Cluster Name         Cluster Serial Number Availability   Authentication
------------------------- --------------------- -------------- --------------
cluster_A 1-80-000011 Available ok
....
. Configurez le groupe DR pour les nœuds IP MetroCluster :
+
`metrocluster configuration-settings dr-group create -partner-cluster`

+
....
cluster_A::> metrocluster configuration-settings dr-group create -partner-cluster
cluster_B -local-node node_A_3-IP -remote-node node_B_3-IP
[Job 259] Job succeeded: DR Group Create is successful.
cluster_A::>
....
. Vérifiez que le groupe DR est créé.
+
`metrocluster configuration-settings dr-group show`

+
....
cluster_A::> metrocluster configuration-settings dr-group show

DR Group ID Cluster                    Node               DR Partner Node
----------- -------------------------- ------------------ ------------------
2           cluster_A
                                       node_A_3-IP        node_B_3-IP
                                       node_A_4-IP        node_B_4-IP
            cluster_B
                                       node_B_3-IP        node_A_3-IP
                                       node_B_4-IP        node_A_4-IP

4 entries were displayed.

cluster_A::>
....
+
Vous remarquerez que le groupe de reprise sur incident des anciens nœuds FC MetroCluster (groupe DR 1) n'est pas répertorié lors de l'exécution du système `metrocluster configuration-settings dr-group show` commande.

+
Vous pouvez utiliser `metrocluster node show` commande sur les deux sites pour répertorier tous les nœuds.

+
....
cluster_A::> metrocluster node show

DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_A
              node_A_1-FC         configured     enabled   normal
              node_A_2-FC         configured     enabled   normal
      cluster_B
              node_B_1-FC         configured     enabled   normal
              node_B_2-FC         configured     enabled   normal
2     cluster_A
              node_A_3-IP      ready to configure
                                                -         -
              node_A_4-IP      ready to configure
                                                -         -

cluster_B::> metrocluster node show

DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_B
              node_B_1-FC         configured     enabled   normal
              node_B_2-FC         configured     enabled   normal
      cluster_A
              node_A_1-FC         configured     enabled   normal
              node_A_2-FC         configured     enabled   normal
2     cluster_B
              node_B_3-IP      ready to configure
                                                -         -
              node_B_4-IP      ready to configure
                                                -         -
....
. Configurez les interfaces IP MetroCluster pour les nœuds IP MetroCluster nouvellement rejoints :
+

CAUTION: N'utilisez pas d'adresses IP 169.254.17.x ou 169.254.18.x lorsque vous créez des interfaces IP MetroCluster pour éviter les conflits avec les adresses IP d'interface générées automatiquement par le système dans la même plage.

+
`metrocluster configuration-settings interface create -cluster-name`

+
Voir link:../install-ip/task_sw_config_configure_clusters.html#configuring-and-connecting-the-metrocluster-ip-interfaces["Configuration et connexion des interfaces IP MetroCluster"] Pour les considérations relatives à la configuration des interfaces IP.

+

NOTE: Vous pouvez configurer les interfaces IP MetroCluster depuis n'importe quel cluster.

+
....
cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_A -home-node node_A_3-IP -home-port e1a -address 172.17.26.10 -netmask 255.255.255.0
[Job 260] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_A -home-node node_A_3-IP -home-port e1b -address 172.17.27.10 -netmask 255.255.255.0
[Job 261] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_A -home-node node_A_4-IP -home-port e1a -address 172.17.26.11 -netmask 255.255.255.0
[Job 262] Job succeeded: Interface Create is successful.

cluster_A::> :metrocluster configuration-settings interface create -cluster-name cluster_A -home-node node_A_4-IP -home-port e1b -address 172.17.27.11 -netmask 255.255.255.0
[Job 263] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_B -home-node node_B_3-IP -home-port e1a -address 172.17.26.12 -netmask 255.255.255.0
[Job 264] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_B -home-node node_B_3-IP -home-port e1b -address 172.17.27.12 -netmask 255.255.255.0
[Job 265] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_B -home-node node_B_4-IP -home-port e1a -address 172.17.26.13 -netmask 255.255.255.0
[Job 266] Job succeeded: Interface Create is successful.

cluster_A::> metrocluster configuration-settings interface create -cluster-name cluster_B -home-node node_B_4-IP -home-port e1b -address 172.17.27.13 -netmask 255.255.255.0
[Job 267] Job succeeded: Interface Create is successful.
....
. Vérifiez que les interfaces IP MetroCluster sont créées :
+
`metrocluster configuration-settings interface show`

+
....
cluster_A::>metrocluster configuration-settings interface show

DR                                                                    Config
Group Cluster Node    Network Address Netmask         Gateway         State
----- ------- ------- --------------- --------------- --------------- ---------
2     cluster_A
             node_A_3-IP
                 Home Port: e1a
                      172.17.26.10    255.255.255.0   -               completed
                 Home Port: e1b
                      172.17.27.10    255.255.255.0   -               completed
              node_A_4-IP
                 Home Port: e1a
                      172.17.26.11    255.255.255.0   -               completed
                 Home Port: e1b
                      172.17.27.11    255.255.255.0   -               completed
      cluster_B
             node_B_3-IP
                 Home Port: e1a
                      172.17.26.13    255.255.255.0   -               completed
                 Home Port: e1b
                      172.17.27.13    255.255.255.0   -               completed
              node_B_3-IP
                 Home Port: e1a
                      172.17.26.12    255.255.255.0   -               completed
                 Home Port: e1b
                      172.17.27.12    255.255.255.0   -               completed
8 entries were displayed.

cluster_A>
....
. Connectez les interfaces IP MetroCluster :
+
`metrocluster configuration-settings connection connect`

+

NOTE: Cette commande peut prendre plusieurs minutes.

+
....
cluster_A::> metrocluster configuration-settings connection connect

cluster_A::>
....
. Vérifiez que les connexions sont correctement établies :
+
`metrocluster configuration-settings connection show`

+
....
cluster_A::> metrocluster configuration-settings connection show

DR                    Source          Destination
Group Cluster Node    Network Address Network Address Partner Type Config State
----- ------- ------- --------------- --------------- ------------ ------------
2     cluster_A
              node_A_3-IP**
                 Home Port: e1a
                      172.17.26.10    172.17.26.11    HA Partner   completed
                 Home Port: e1a
                      172.17.26.10    172.17.26.12    DR Partner   completed
                 Home Port: e1a
                      172.17.26.10    172.17.26.13    DR Auxiliary completed
                 Home Port: e1b
                      172.17.27.10    172.17.27.11    HA Partner   completed
                 Home Port: e1b
                      172.17.27.10    172.17.27.12    DR Partner   completed
                 Home Port: e1b
                      172.17.27.10    172.17.27.13    DR Auxiliary completed
              node_A_4-IP
                 Home Port: e1a
                      172.17.26.11    172.17.26.10    HA Partner   completed
                 Home Port: e1a
                      172.17.26.11    172.17.26.13    DR Partner   completed
                 Home Port: e1a
                      172.17.26.11    172.17.26.12    DR Auxiliary completed
                 Home Port: e1b
                      172.17.27.11    172.17.27.10    HA Partner   completed
                 Home Port: e1b
                      172.17.27.11    172.17.27.13    DR Partner   completed
                 Home Port: e1b
                      172.17.27.11    172.17.27.12    DR Auxiliary completed

DR                    Source          Destination
Group Cluster Node    Network Address Network Address Partner Type Config State
----- ------- ------- --------------- --------------- ------------ ------------
2     cluster_B
              node_B_4-IP
                 Home Port: e1a
                      172.17.26.13    172.17.26.12    HA Partner   completed
                 Home Port: e1a
                      172.17.26.13    172.17.26.11    DR Partner   completed
                 Home Port: e1a
                      172.17.26.13    172.17.26.10    DR Auxiliary completed
                 Home Port: e1b
                      172.17.27.13    172.17.27.12    HA Partner   completed
                 Home Port: e1b
                      172.17.27.13    172.17.27.11    DR Partner   completed
                 Home Port: e1b
                      172.17.27.13    172.17.27.10    DR Auxiliary completed
              node_B_3-IP
                 Home Port: e1a
                      172.17.26.12    172.17.26.13    HA Partner   completed
                 Home Port: e1a
                      172.17.26.12    172.17.26.10    DR Partner   completed
                 Home Port: e1a
                      172.17.26.12    172.17.26.11    DR Auxiliary completed
                 Home Port: e1b
                      172.17.27.12    172.17.27.13    HA Partner   completed
                 Home Port: e1b
                      172.17.27.12    172.17.27.10    DR Partner   completed
                 Home Port: e1b
                      172.17.27.12    172.17.27.11    DR Auxiliary completed
24 entries were displayed.

cluster_A::>
....
. Vérifiez le partitionnement et l'autoassignation des disques :
+
`disk show -pool Pool1`

+
....
cluster_A::> disk show -pool Pool1
                     Usable           Disk    Container   Container
Disk                   Size Shelf Bay Type    Type        Name      Owner
---------------- ---------- ----- --- ------- ----------- --------- --------
1.10.4                    -    10   4 SAS     remote      -         node_B_2
1.10.13                   -    10  13 SAS     remote      -         node_B_2
1.10.14                   -    10  14 SAS     remote      -         node_B_1
1.10.15                   -    10  15 SAS     remote      -         node_B_1
1.10.16                   -    10  16 SAS     remote      -         node_B_1
1.10.18                   -    10  18 SAS     remote      -         node_B_2
...
2.20.0              546.9GB    20   0 SAS     aggregate   aggr0_rha1_a1 node_a_1
2.20.3              546.9GB    20   3 SAS     aggregate   aggr0_rha1_a2 node_a_2
2.20.5              546.9GB    20   5 SAS     aggregate   rha1_a1_aggr1 node_a_1
2.20.6              546.9GB    20   6 SAS     aggregate   rha1_a1_aggr1 node_a_1
2.20.7              546.9GB    20   7 SAS     aggregate   rha1_a2_aggr1 node_a_2
2.20.10             546.9GB    20  10 SAS     aggregate   rha1_a1_aggr1 node_a_1
...
43 entries were displayed.
cluster_A::>
....
+

NOTE: Sur les systèmes configurés pour le partitionnement de disque avancé, le type de conteneur est « partagé » plutôt que « distant », comme indiqué dans la sortie de l'exemple.

. Mettez en miroir les agrégats racine :
+
`storage aggregate mirror -aggregate aggr0_node_A_3_IP`

+

NOTE: Cette étape doit être effectuée sur chaque nœud IP MetroCluster.

+
....
cluster_A::> aggr mirror -aggregate aggr0_node_A_3_IP

Info: Disks would be added to aggregate "aggr0_node_A_3_IP"on node "node_A_3-IP"
      in the following manner:

      Second Plex

        RAID Group rg0, 3 disks (block checksum, raid_dp)
                                                            Usable Physical
          Position   Disk                      Type           Size     Size
          ---------- ------------------------- ---------- -------- --------
          dparity    4.20.0                    SAS               -        -
          parity     4.20.3                    SAS               -        -
          data       4.20.1                    SAS         546.9GB  558.9GB

      Aggregate capacity available for volume use would be 467.6GB.

Do you want to continue? {y|n}: y

cluster_A::>
....
. Vérifier que les agrégats racine sont mis en miroir :
+
`storage aggregate show`

+
....
cluster_A::> aggr show

Aggregate     Size Available Used% State   #Vols  Nodes            RAID Status
--------- -------- --------- ----- ------- ------ ---------------- ------------
aggr0_node_A_1_FC
           349.0GB   16.84GB   95% online       1 node_A_1-FC      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr0_node_A_2_FC
           349.0GB   16.84GB   95% online       1 node_A_2-FC      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr0_node_A_3_IP
           467.6GB   22.63GB   95% online       1 node_A_3-IP      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr0_node_A_4_IP
           467.6GB   22.62GB   95% online       1 node_A_4-IP      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr_data_a1
            1.02TB    1.01TB    1% online       1 node_A_1-FC      raid_dp,
                                                                   mirrored,
                                                                   normal
aggr_data_a2
            1.02TB    1.01TB    1% online       1 node_A_2-FC      raid_dp,
                                                                   mirrored,
....




== Finalisation de l'ajout des nœuds IP MetroCluster

Vous devez intégrer le nouveau groupe de reprise après incident à la configuration MetroCluster et créer des agrégats de données en miroir sur les nouveaux nœuds.

.Étapes
. Configurez le MetroCluster selon qu'il existe un ou plusieurs agrégats de données sur les deux clusters :
+
|===


| Si votre configuration MetroCluster possède... | Alors, procédez comme ça... 


 a| 
Plusieurs agrégats de données sur les deux clusters
 a| 
Depuis n'importe quelle invite de nœud, configurer MetroCluster :

`metrocluster configure <node-name>`


NOTE: Vous devez exécuter `metrocluster configure` et *pas* `metrocluster configure -refresh true`



 a| 
Un seul agrégat de données en miroir sur les deux clusters
 a| 
.. Depuis l'invite de n'importe quel nœud, passez au niveau de privilège avancé :
+
`set -privilege advanced`

+
Vous devez répondre avec `y` lorsque vous êtes invité à continuer en mode avancé et que vous voyez l'invite du mode avancé (*).

.. Configurez le MetroCluster avec le `-allow-with-one-aggregate true` paramètre :
+
`metrocluster configure -allow-with-one-aggregate true -node-name <node-name>`

.. Retour au niveau de privilège admin :
+
`set -privilege admin`



|===
+

NOTE: Il est recommandé d'avoir plusieurs agrégats de données en miroir. En effet, lorsqu'il n'existe qu'un seul agrégat en miroir, la protection est moindre, car les volumes de métadonnées sont situés sur le même agrégat plutôt que sur des agrégats distincts.

. Rebooter chacun des nouveaux nœuds :
+
`node reboot -node <node_name> -inhibit-takeover true`

+

NOTE: Vous n'avez pas besoin de redémarrer les nœuds dans un ordre spécifique, mais vous devez attendre qu'un nœud soit entièrement démarré et que toutes les connexions soient établies avant de redémarrer le nœud suivant.

. Vérifier que les nœuds sont ajoutés à leur groupe de reprise sur incident :
+
`metrocluster node show`

+
....
cluster_A::> metrocluster node show

DR                               Configuration  DR
Group Cluster Node               State          Mirroring Mode
----- ------- ------------------ -------------- --------- --------------------
1     cluster_A
              node-A-1-FC        configured     enabled   normal
              node-A-2-FC        configured     enabled   normal
      Cluster-B
              node-B-1-FC        configured     enabled   normal
              node-B-2-FC        configured     enabled   normal
2     cluster_A
              node-A-3-IP        configured     enabled   normal
              node-A-4-IP        configured     enabled   normal
      Cluster-B
              node-B-3-IP        configured     enabled   normal
              node-B-4-IP        configured     enabled   normal
8 entries were displayed.

cluster_A::>
....
. Créez des agrégats de données en miroir sur chacun des nouveaux nœuds MetroCluster :
+
`storage aggregate create -aggregate aggregate-name -node node-name -diskcount no-of-disks -mirror true`

+

NOTE: Vous devez créer au moins un agrégat de données en miroir par site. Il est recommandé d'avoir deux agrégats de données en miroir par site sur des nœuds IP MetroCluster pour héberger les volumes MDV. Cependant, un seul agrégat par site est pris en charge (mais non recommandé). Il est acceptable qu'un site du MetroCluster dispose d'un seul agrégat de données en miroir et que l'autre site possède plusieurs agrégats en miroir.

+
L'exemple suivant montre la création d'un agrégat sur node_A_3-IP.

+
....
cluster_A::> storage aggregate create -aggregate data_a3 -node node_A_3-IP -diskcount 10 -mirror t

Info: The layout for aggregate "data_a3" on node "node_A_3-IP" would be:

      First Plex

        RAID Group rg0, 5 disks (block checksum, raid_dp)
                                                            Usable Physical
          Position   Disk                      Type           Size     Size
          ---------- ------------------------- ---------- -------- --------
          dparity    5.10.15                   SAS               -        -
          parity     5.10.16                   SAS               -        -
          data       5.10.17                   SAS         546.9GB  547.1GB
          data       5.10.18                   SAS         546.9GB  558.9GB
          data       5.10.19                   SAS         546.9GB  558.9GB

      Second Plex

        RAID Group rg0, 5 disks (block checksum, raid_dp)
                                                            Usable Physical
          Position   Disk                      Type           Size     Size
          ---------- ------------------------- ---------- -------- --------
          dparity    4.20.17                   SAS               -        -
          parity     4.20.14                   SAS               -        -
          data       4.20.18                   SAS         546.9GB  547.1GB
          data       4.20.19                   SAS         546.9GB  547.1GB
          data       4.20.16                   SAS         546.9GB  547.1GB

      Aggregate capacity available for volume use would be 1.37TB.

Do you want to continue? {y|n}: y
[Job 440] Job succeeded: DONE

cluster_A::>
....
. Vérifier que tous les nœuds du cluster fonctionnent correctement :
+
`cluster show`

+
La sortie doit s'afficher `true` pour le `health` pour tous les nœuds.

. Vérifier que le basculement est possible et que les nœuds sont connectés en exécutant la commande suivante sur les deux clusters :
+
`storage failover show`

+
[listing]
----
cluster_A::> storage failover show
                                    Takeover
Node           Partner              Possible    State Description
-------------- -------------------- ---------   ------------------
Node_FC_1      Node_FC_2              true      Connected to Node_FC_2
Node_FC_2      Node_FC_1              true      Connected to Node_FC_1
Node_IP_1      Node_IP_2              true      Connected to Node_IP_2
Node_IP_2      Node_IP_1              true      Connected to Node_IP_1
----
. Vérifier que tous les disques connectés aux nœuds IP MetroCluster nouvellement joints sont présents :
+
`disk show`

. Vérifiez l'état de santé de la configuration MetroCluster en exécutant les commandes suivantes :
+
.. `metrocluster check run`
.. `metrocluster check show`
.. `metrocluster interconnect mirror show`
.. `metrocluster interconnect adapter show`


. Déplacez les volumes MDV_CRS des anciens nœuds vers les nouveaux nœuds du privilège avancé.
+
.. Afficher les volumes pour identifier les volumes MDV :
+

NOTE: Si vous disposez d'un seul agrégat de données en miroir par site, déplacez les deux volumes MDV vers cet agrégat unique. Si vous disposez de deux agrégats de données en miroir ou plus, déplacez chaque volume MDV vers un agrégat différent.

+
L'exemple suivant montre les volumes MDV dans le volume show output :

+
....
cluster_A::> volume show
Vserver   Volume       Aggregate    State      Type       Size  Available Used%
--------- ------------ ------------ ---------- ---- ---------- ---------- -----
...

cluster_A   MDV_CRS_2c78e009ff5611e9b0f300a0985ef8c4_A
                       aggr_b1      -          RW            -          -     -
cluster_A   MDV_CRS_2c78e009ff5611e9b0f300a0985ef8c4_B
                       aggr_b2      -          RW            -          -     -
cluster_A   MDV_CRS_d6b0b313ff5611e9837100a098544e51_A
                       aggr_a1      online     RW         10GB     9.50GB    0%
cluster_A   MDV_CRS_d6b0b313ff5611e9837100a098544e51_B
                       aggr_a2      online     RW         10GB     9.50GB    0%
...
11 entries were displayed.mple
....
.. Définissez le niveau de privilège avancé :
+
`set -privilege advanced`

.. Déplacer les volumes MDV, un par un :
+
`volume move start -volume mdv-volume -destination-aggregate aggr-on-new-node -vserver vserver-name`

+
L'exemple suivant montre la commande et la sortie pour déplacer MDV_CRS_d6b0b313ff5611e9837100a098544e51_A vers agréger data_a3 sur le noeud_A_3.

+
....
cluster_A::*> vol move start -volume MDV_CRS_d6b0b313ff5611e9837100a098544e51_A -destination-aggregate data_a3 -vserver cluster_A

Warning: You are about to modify the system volume
         "MDV_CRS_d6b0b313ff5611e9837100a098544e51_A". This might cause severe
         performance or stability problems. Do not proceed unless directed to
         do so by support. Do you want to proceed? {y|n}: y
[Job 494] Job is queued: Move "MDV_CRS_d6b0b313ff5611e9837100a098544e51_A" in Vserver "cluster_A" to aggregate "data_a3". Use the "volume move show -vserver cluster_A -volume MDV_CRS_d6b0b313ff5611e9837100a098544e51_A" command to view the status of this operation.
....
.. Utilisez la commande volume show pour vérifier que le volume MDV a bien été déplacé :
+
`volume show mdv-name`

+
Le résultat suivant indique que le volume MDV a été déplacé avec succès.

+
....
cluster_A::*> vol show MDV_CRS_d6b0b313ff5611e9837100a098544e51_B
Vserver     Volume       Aggregate    State      Type       Size  Available Used%
---------   ------------ ------------ ---------- ---- ---------- ---------- -----
cluster_A   MDV_CRS_d6b0b313ff5611e9837100a098544e51_B
                       aggr_a2      online     RW         10GB     9.50GB    0%
....
.. Revenir en mode admin:
+
`set -privilege admin`




